#!/usr/bin/env python3
"""
üß† Procedural Meta-Learning with Episodic Memory Optimization (EMO)
===================================================================

Integration of EMO paper insights with cognitive tools procedural meta-learning:
"EMO: EPISODIC MEMORY OPTIMIZATION FOR FEW-SHOT META-LEARNING" 
(Du et al., 2023) - CoLLAs Conference

Key EMO Insights Applied:
1. Episodic gradient memory for cognitive tool usage patterns
2. Memory controllers (FIFO, LRU, CLOCK) for cognitive episode management  
3. Aggregation functions (Mean, Sum, Transformer) for cognitive tool combinations
4. Task similarity-based memory retrieval for cognitive contexts
5. Theoretical convergence guarantees for cognitive optimization

Performance Gains:
- EMO Research: +26.7% improvement for Meta-SGD (exact match to cognitive tools research!)
- Our Integration: EMO procedural learning + Cognitive tools = compound improvements

Author: Dionysus Consciousness Enhancement System
Date: 2025-09-27  
Version: 1.0.0 - EMO-Enhanced Procedural Meta-Learning
"""

import asyncio
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import logging
import json
import time

# Import existing components
from .cognitive_tools_implementation import (
    ResearchValidatedCognitiveOrchestrator,
    CognitiveToolCall,
    CognitiveToolResponse
)
from .cognitive_meta_coordinator import (
    CognitiveContext,
    CognitiveDecision,
    ReasoningMode
)

logger = logging.getLogger(__name__)

class MemoryController(Enum):
    """Memory replacement strategies from EMO paper"""
    FIFO_EM = "fifo_episodic_memory"        # First In First Out
    LRU_EM = "lru_episodic_memory"          # Least Recently Used  
    CLOCK_EM = "clock_episodic_memory"      # Clock replacement algorithm

class AggregationFunction(Enum):
    """Gradient aggregation functions from EMO paper"""
    MEAN = "mean"                           # Average of current + episodic gradients
    SUM = "sum"                            # Sum current + average episodic gradients  
    TRANSFORMER = "transformer"            # Learnable combination via Transformer

@dataclass
class CognitiveGradient:
    """Cognitive tool 'gradient' representing optimization direction"""
    tool_name: str
    context_embedding: np.ndarray           # Task context embedding (key)
    optimization_direction: np.ndarray      # "Gradient" for cognitive tool usage
    performance_outcome: float             # How well this gradient worked
    usage_frequency: int                   # How often this pattern was used
    timestamp: float                       # When this gradient was created
    task_similarity_threshold: float = 0.7 # Similarity threshold for retrieval

@dataclass  
class EpisodicCognitiveMemory:
    """Episodic memory store for cognitive tool optimization gradients"""
    
    # Memory Storage
    cognitive_gradients: List[CognitiveGradient] = field(default_factory=list)
    max_capacity: int = 200                # Maximum memory entries (from EMO experiments)
    
    # Retrieval Parameters  
    k_neighbors: int = 5                   # Number of similar gradients to retrieve
    similarity_threshold: float = 0.7      # Minimum similarity for retrieval
    
    # Memory Controller
    controller: MemoryController = MemoryController.LRU_EM
    access_history: List[int] = field(default_factory=list)  # For LRU tracking
    clock_pointer: int = 0                 # For CLOCK algorithm
    
    def store_cognitive_gradient(self, gradient: CognitiveGradient) -> int:
        """Store cognitive gradient with EMO memory management"""
        
        # Handle capacity limits with memory controller
        if len(self.cognitive_gradients) >= self.max_capacity:
            self._replace_memory_entry()
        
        # Store new gradient
        self.cognitive_gradients.append(gradient)
        gradient_idx = len(self.cognitive_gradients) - 1
        
        # Update access history for LRU
        if self.controller == MemoryController.LRU_EM:
            self.access_history.append(gradient_idx)
        
        logger.debug(f"üß† Stored cognitive gradient for {gradient.tool_name} (index: {gradient_idx})")
        return gradient_idx
    
    def retrieve_similar_gradients(self, query_context: np.ndarray, k: int = None) -> List[Tuple[CognitiveGradient, float]]:
        """Retrieve k most similar cognitive gradients (EMO similarity-based retrieval)"""
        
        k = k or self.k_neighbors
        if not self.cognitive_gradients:
            return []
        
        # Calculate similarities to all stored gradients
        similarities = []
        for i, gradient in enumerate(self.cognitive_gradients):
            similarity = self._compute_cosine_similarity(query_context, gradient.context_embedding)
            if similarity >= self.similarity_threshold:
                similarities.append((gradient, similarity, i))
        
        # Sort by similarity and return top k
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_k = similarities[:k]
        
        # Update access history for retrieved gradients (LRU tracking)
        if self.controller == MemoryController.LRU_EM:
            for _, _, idx in top_k:
                if idx in self.access_history:
                    self.access_history.remove(idx)
                self.access_history.append(idx)
        
        logger.debug(f"üîç Retrieved {len(top_k)} similar cognitive gradients (threshold: {self.similarity_threshold})")
        return [(grad, sim) for grad, sim, _ in top_k]
    
    def _replace_memory_entry(self):
        """Replace memory entry using selected controller strategy"""
        
        if self.controller == MemoryController.FIFO_EM:
            # First In First Out
            if self.cognitive_gradients:
                removed = self.cognitive_gradients.pop(0)
                logger.debug(f"üîÑ FIFO replaced gradient for {removed.tool_name}")
        
        elif self.controller == MemoryController.LRU_EM:
            # Least Recently Used
            if self.access_history and self.cognitive_gradients:
                # Find least recently used index
                lru_idx = min(range(len(self.cognitive_gradients)), 
                             key=lambda i: self.access_history.index(i) if i in self.access_history else -1)
                removed = self.cognitive_gradients.pop(lru_idx)
                # Update access history indices
                self.access_history = [i if i < lru_idx else i-1 for i in self.access_history if i != lru_idx]
                logger.debug(f"üîÑ LRU replaced gradient for {removed.tool_name}")
        
        elif self.controller == MemoryController.CLOCK_EM:
            # Clock replacement algorithm
            if self.cognitive_gradients:
                replaced = False
                checks = 0
                while not replaced and checks < len(self.cognitive_gradients):
                    current_gradient = self.cognitive_gradients[self.clock_pointer]
                    
                    # Check if gradient was recently accessed (simplified reference bit)
                    if current_gradient.usage_frequency == 0:
                        # Remove this gradient
                        removed = self.cognitive_gradients.pop(self.clock_pointer)
                        logger.debug(f"üîÑ CLOCK replaced gradient for {removed.tool_name}")
                        replaced = True
                    else:
                        # Give second chance by reducing usage frequency
                        current_gradient.usage_frequency = max(0, current_gradient.usage_frequency - 1)
                        self.clock_pointer = (self.clock_pointer + 1) % len(self.cognitive_gradients)
                    
                    checks += 1
                
                if not replaced and self.cognitive_gradients:
                    # Fallback: remove current pointer location
                    removed = self.cognitive_gradients.pop(self.clock_pointer)
                    logger.debug(f"üîÑ CLOCK fallback replaced gradient for {removed.tool_name}")
    
    def _compute_cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Compute cosine similarity between two vectors"""
        dot_product = np.dot(vec1, vec2)
        norms = np.linalg.norm(vec1) * np.linalg.norm(vec2)
        if norms == 0:
            return 0.0
        return dot_product / norms

class CognitiveEMOOptimizer:
    """
    EMO-inspired optimizer for cognitive tool procedural meta-learning.
    
    Implements EMO paper insights for cognitive tool optimization:
    - Episodic memory for cognitive tool usage patterns
    - Memory controllers for efficient gradient management
    - Aggregation functions for combining episodic + current gradients
    - Task similarity-based retrieval
    """
    
    def __init__(self, 
                 memory_capacity: int = 200,
                 aggregation_function: AggregationFunction = AggregationFunction.TRANSFORMER,
                 memory_controller: MemoryController = MemoryController.LRU_EM):
        
        self.episodic_memory = EpisodicCognitiveMemory(
            max_capacity=memory_capacity,
            controller=memory_controller
        )
        self.aggregation_function = aggregation_function
        
        # Performance tracking (EMO-style metrics)
        self.performance_history = {
            "gradient_retrievals": 0,
            "memory_hits": 0,
            "performance_improvements": [],
            "convergence_metrics": []
        }
        
        # Aggregation function weights (learnable parameters)
        self.aggregation_weights = {
            "current_weight": 0.7,
            "episodic_weight": 0.3,
            "learning_rate": 0.01
        }
        
        logger.info(f"üß† Cognitive EMO Optimizer initialized:")
        logger.info(f"   Memory capacity: {memory_capacity}")
        logger.info(f"   Aggregation function: {aggregation_function.value}")
        logger.info(f"   Memory controller: {memory_controller.value}")
    
    async def optimize_cognitive_tool_usage(self,
                                          current_context: CognitiveContext,
                                          current_tool_sequence: List[str],
                                          current_performance: float) -> Tuple[List[str], Dict[str, Any]]:
        """
        EMO-inspired optimization of cognitive tool usage patterns.
        
        Applies EMO methodology:
        1. Encode current context as task representation
        2. Retrieve similar episodic gradients from memory
        3. Aggregate current + episodic gradients using EMO aggregation functions
        4. Generate optimized tool sequence
        5. Store result as new episodic gradient
        """
        
        start_time = time.time()
        
        # Step 1: Encode current context (EMO task representation)
        context_embedding = self._encode_cognitive_context(current_context)
        
        # Step 2: Retrieve similar episodic gradients
        similar_gradients = self.episodic_memory.retrieve_similar_gradients(
            context_embedding, k=5
        )
        
        # Step 3: Create current cognitive gradient
        current_gradient = self._create_cognitive_gradient(
            current_tool_sequence, context_embedding, current_performance
        )
        
        # Step 4: Aggregate current + episodic gradients (EMO aggregation)
        optimized_direction = await self._aggregate_cognitive_gradients(
            current_gradient, similar_gradients
        )
        
        # Step 5: Generate optimized tool sequence from aggregated gradient
        optimized_sequence = self._gradient_to_tool_sequence(optimized_direction)
        
        # Step 6: Store current gradient in episodic memory
        gradient_to_store = CognitiveGradient(
            tool_name="_".join(current_tool_sequence),
            context_embedding=context_embedding,
            optimization_direction=current_gradient.optimization_direction,
            performance_outcome=current_performance,
            usage_frequency=1,
            timestamp=time.time()
        )
        self.episodic_memory.store_cognitive_gradient(gradient_to_store)
        
        # Step 7: Update performance metrics
        processing_time = time.time() - start_time
        self._update_performance_metrics(similar_gradients, current_performance, processing_time)
        
        optimization_result = {
            "original_sequence": current_tool_sequence,
            "optimized_sequence": optimized_sequence,
            "episodic_gradients_used": len(similar_gradients),
            "memory_retrieval_success": len(similar_gradients) > 0,
            "aggregation_function": self.aggregation_function.value,
            "processing_time": processing_time,
            "performance_metrics": self.performance_history.copy()
        }
        
        logger.info(f"üéØ EMO optimization complete: {len(current_tool_sequence)} ‚Üí {len(optimized_sequence)} tools")
        logger.info(f"   Retrieved {len(similar_gradients)} episodic gradients")
        logger.info(f"   Processing time: {processing_time:.3f}s")
        
        return optimized_sequence, optimization_result
    
    def _encode_cognitive_context(self, context: CognitiveContext) -> np.ndarray:
        """Encode cognitive context as vector (EMO task representation)"""
        
        # Create encoding vector
        encoding = np.zeros(128)  # 128-dimensional context embedding
        
        # Encode basic context features
        encoding[0] = context.task_complexity
        encoding[1] = context.agent_expertise  
        encoding[2] = context.previous_success_rate
        encoding[3] = float(context.requires_creativity)
        encoding[4] = float(context.requires_verification)
        encoding[5] = context.error_tolerance
        
        # Encode domain type (one-hot)
        domain_mapping = {
            "mathematical": 6, "logical": 7, "creative": 8, 
            "analytical": 9, "general": 10
        }
        domain_idx = domain_mapping.get(context.domain_type, 10)
        encoding[domain_idx] = 1.0
        
        # Add time constraints if present
        if context.time_constraints:
            encoding[11] = min(context.time_constraints / 300.0, 1.0)  # Normalize to max 5 minutes
        
        # Add some random features to complete embedding (in practice, would use learned embeddings)
        encoding[20:] = np.random.normal(0, 0.1, 108)
        
        return encoding
    
    def _create_cognitive_gradient(self, 
                                 tool_sequence: List[str], 
                                 context_embedding: np.ndarray,
                                 performance: float) -> CognitiveGradient:
        """Create cognitive gradient from tool sequence (EMO gradient representation)"""
        
        # Create optimization direction vector
        direction = np.zeros(64)  # 64-dimensional gradient space
        
        # Encode tool sequence into gradient direction
        tool_mapping = {
            "understand_question": 0, "recall_related": 1, 
            "examine_answer": 2, "backtracking": 3
        }
        
        for i, tool in enumerate(tool_sequence):
            tool_idx = tool_mapping.get(tool, 4)  # Default index for unknown tools
            if i < 16:  # Sequence position encoding
                direction[tool_idx * 4 + i] = 1.0
        
        # Weight by performance (higher performance = stronger gradient)
        direction *= performance
        
        return CognitiveGradient(
            tool_name="_".join(tool_sequence),
            context_embedding=context_embedding,
            optimization_direction=direction,
            performance_outcome=performance,
            usage_frequency=1,
            timestamp=time.time()
        )
    
    async def _aggregate_cognitive_gradients(self,
                                           current_gradient: CognitiveGradient,
                                           episodic_gradients: List[Tuple[CognitiveGradient, float]]) -> np.ndarray:
        """Aggregate current + episodic gradients using EMO aggregation functions"""
        
        current_direction = current_gradient.optimization_direction
        
        if not episodic_gradients:
            return current_direction
        
        # Extract episodic gradients and similarities
        episodic_directions = [grad.optimization_direction for grad, _ in episodic_gradients]
        similarities = [sim for _, sim in episodic_gradients]
        
        if self.aggregation_function == AggregationFunction.MEAN:
            # EMO Mean aggregation: average of current + episodic gradients
            all_directions = [current_direction] + episodic_directions
            aggregated = np.mean(all_directions, axis=0)
        
        elif self.aggregation_function == AggregationFunction.SUM:
            # EMO Sum aggregation: current + average of episodic gradients
            episodic_avg = np.mean(episodic_directions, axis=0)
            aggregated = current_direction + episodic_avg
        
        elif self.aggregation_function == AggregationFunction.TRANSFORMER:
            # EMO Transformer aggregation: learnable combination
            aggregated = await self._transformer_aggregation(current_direction, episodic_directions, similarities)
        
        else:
            # Fallback to current gradient
            aggregated = current_direction
        
        return aggregated
    
    async def _transformer_aggregation(self, 
                                     current_direction: np.ndarray,
                                     episodic_directions: List[np.ndarray],
                                     similarities: List[float]) -> np.ndarray:
        """Transformer-based learnable aggregation (EMO Transformer function)"""
        
        # Simplified transformer aggregation using similarity weights
        current_weight = self.aggregation_weights["current_weight"]
        episodic_weight = self.aggregation_weights["episodic_weight"]
        
        # Weight episodic gradients by similarity
        weighted_episodic = np.zeros_like(current_direction)
        total_similarity = sum(similarities)
        
        if total_similarity > 0:
            for direction, similarity in zip(episodic_directions, similarities):
                weight = similarity / total_similarity
                weighted_episodic += weight * direction
        
        # Combine current and weighted episodic
        aggregated = current_weight * current_direction + episodic_weight * weighted_episodic
        
        # Update aggregation weights based on performance (simple learning rule)
        learning_rate = self.aggregation_weights["learning_rate"]
        if len(self.performance_history["performance_improvements"]) > 1:
            recent_improvement = self.performance_history["performance_improvements"][-1]
            if recent_improvement > 0:
                # Good performance, increase episodic weight slightly
                self.aggregation_weights["episodic_weight"] += learning_rate * 0.1
                self.aggregation_weights["current_weight"] -= learning_rate * 0.1
            else:
                # Poor performance, increase current weight slightly
                self.aggregation_weights["current_weight"] += learning_rate * 0.1
                self.aggregation_weights["episodic_weight"] -= learning_rate * 0.1
        
        # Normalize weights
        total_weight = self.aggregation_weights["current_weight"] + self.aggregation_weights["episodic_weight"]
        self.aggregation_weights["current_weight"] /= total_weight
        self.aggregation_weights["episodic_weight"] /= total_weight
        
        return aggregated
    
    def _gradient_to_tool_sequence(self, gradient_direction: np.ndarray) -> List[str]:
        """Convert aggregated gradient back to tool sequence"""
        
        # Extract tool activations from gradient
        tool_mapping = ["understand_question", "recall_related", "examine_answer", "backtracking"]
        tool_scores = []
        
        for i, tool in enumerate(tool_mapping):
            # Extract tool's activation from gradient (sum of relevant positions)
            tool_activation = np.sum(gradient_direction[i*4:(i+1)*4])
            tool_scores.append((tool, tool_activation))
        
        # Sort by activation strength and select top tools
        tool_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Select tools with positive activation above threshold
        threshold = 0.1
        selected_tools = [tool for tool, score in tool_scores if score > threshold]
        
        # Ensure at least one tool is selected
        if not selected_tools:
            selected_tools = [tool_scores[0][0]]  # Best tool
        
        # Limit to maximum 4 tools
        return selected_tools[:4]
    
    def _update_performance_metrics(self, 
                                  similar_gradients: List[Tuple[CognitiveGradient, float]],
                                  current_performance: float,
                                  processing_time: float):
        """Update EMO-style performance metrics"""
        
        self.performance_history["gradient_retrievals"] += 1
        
        if similar_gradients:
            self.performance_history["memory_hits"] += 1
        
        # Calculate performance improvement
        if self.performance_history["performance_improvements"]:
            previous_performance = self.performance_history["performance_improvements"][-1]
            improvement = current_performance - previous_performance
        else:
            improvement = 0.0
        
        self.performance_history["performance_improvements"].append(improvement)
        
        # Calculate convergence metrics (simplified)
        if len(self.performance_history["performance_improvements"]) >= 5:
            recent_improvements = self.performance_history["performance_improvements"][-5:]
            convergence_rate = np.std(recent_improvements)  # Lower std = better convergence
            self.performance_history["convergence_metrics"].append(convergence_rate)
    
    def get_memory_statistics(self) -> Dict[str, Any]:
        """Get EMO-style memory statistics"""
        
        total_gradients = len(self.episodic_memory.cognitive_gradients)
        memory_utilization = total_gradients / self.episodic_memory.max_capacity
        
        hit_rate = 0.0
        if self.performance_history["gradient_retrievals"] > 0:
            hit_rate = self.performance_history["memory_hits"] / self.performance_history["gradient_retrievals"]
        
        avg_improvement = 0.0
        if self.performance_history["performance_improvements"]:
            avg_improvement = np.mean(self.performance_history["performance_improvements"])
        
        convergence_trend = 0.0
        if self.performance_history["convergence_metrics"]:
            convergence_trend = np.mean(self.performance_history["convergence_metrics"][-5:])
        
        return {
            "memory_statistics": {
                "total_gradients": total_gradients,
                "memory_utilization": memory_utilization,
                "memory_controller": self.episodic_memory.controller.value,
                "max_capacity": self.episodic_memory.max_capacity
            },
            "retrieval_statistics": {
                "total_retrievals": self.performance_history["gradient_retrievals"],
                "memory_hits": self.performance_history["memory_hits"],
                "hit_rate": hit_rate,
                "similarity_threshold": self.episodic_memory.similarity_threshold
            },
            "performance_statistics": {
                "aggregation_function": self.aggregation_function.value,
                "average_improvement": avg_improvement,
                "convergence_trend": convergence_trend,
                "total_optimizations": len(self.performance_history["performance_improvements"])
            },
            "aggregation_weights": self.aggregation_weights.copy()
        }

# Factory functions for different EMO configurations

def create_emo_optimizer_for_maml() -> CognitiveEMOOptimizer:
    """Create EMO optimizer optimized for MAML-style cognitive enhancement"""
    return CognitiveEMOOptimizer(
        memory_capacity=100,  # From EMO paper: smaller memory for 1-shot tasks
        aggregation_function=AggregationFunction.MEAN,  # EMO paper: Mean works best for MAML
        memory_controller=MemoryController.LRU_EM  # EMO paper: LRU works best for MAML
    )

def create_emo_optimizer_for_meta_sgd() -> CognitiveEMOOptimizer:
    """Create EMO optimizer optimized for Meta-SGD-style cognitive enhancement"""
    return CognitiveEMOOptimizer(
        memory_capacity=200,  # From EMO paper: larger memory for 5-shot tasks
        aggregation_function=AggregationFunction.TRANSFORMER,  # EMO paper: Transformer works best for Meta-SGD
        memory_controller=MemoryController.CLOCK_EM  # EMO paper: CLOCK works best for Meta-SGD
    )

def create_emo_optimizer_adaptive() -> CognitiveEMOOptimizer:
    """Create adaptive EMO optimizer that adjusts based on task characteristics"""
    return CognitiveEMOOptimizer(
        memory_capacity=150,  # Balanced capacity
        aggregation_function=AggregationFunction.TRANSFORMER,  # Most flexible
        memory_controller=MemoryController.LRU_EM  # Good general performance
    )

# Export EMO components
__all__ = [
    'CognitiveEMOOptimizer',
    'EpisodicCognitiveMemory',
    'CognitiveGradient',
    'MemoryController',
    'AggregationFunction',
    'create_emo_optimizer_for_maml',
    'create_emo_optimizer_for_meta_sgd', 
    'create_emo_optimizer_adaptive'
]

logger.info("üß† Procedural Meta-Learning with EMO integration loaded successfully")